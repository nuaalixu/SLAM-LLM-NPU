dataset_config:
  prompt: 'Transcribe speech to text. '
  normalize: true
  dataset: slidespeech_dataset
  input_type: raw
  use_ocr: true
train_config:
  enable_fsdp: false
  enable_ddp: true
  use_fp16: true
  model_name: mala_asr
  num_epochs: 5
  freeze_encoder: true
  freeze_llm: true
  batching_strategy: custom
  warmup_steps: 1000
  total_steps: 110000
  lr: 5.0e-05
  validation_interval: 2000
  batch_size_training: 6
  val_batch_size: 6
  num_workers_dataloader: 2
  output_dir: /aistor/aispeech/hpc_stor01/home/fangyangui/workingspace/github/SLAM-LLM-NPU/examples/aispeech_asr/exp-20250413
deepspeed_config: /aistor/aispeech/hpc_stor01/home/fangyangui/workingspace/github/SLAM-LLM-NPU/examples/aispeech_asr/conf/ds_config.json
model_config:
  llm_name: vicuna-7b-v1.5
  llm_path: /aistor/aispeech/hpc_stor01/home/fangyangui/workingspace/model/vicuna-7b-v1.5
  llm_dim: 4096
  encoder_name: wavlm
  normalize: true
  encoder_projector_ds_rate: 5
  encoder_path: /aistor/aispeech/hpc_stor01/home/fangyangui/workingspace/model/wavlm/WavLM-Large.pt
  encoder_dim: 1024
  encoder_projector: cov1d-linear
metric: acc
